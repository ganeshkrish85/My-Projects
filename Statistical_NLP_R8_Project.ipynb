{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Tip06UL3uJnO",
    "outputId": "5d85d2a0-d7e2-40d3-ffef-e5e0f0af3d0c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ganesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import f1_score\n",
    "import nltk\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ganesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  \n",
       "0             Info has been found (+/- 100 pages,...  \n",
       "1             These are the team members:   Drewe...  \n",
       "2             In het kader van kernfusie op aarde...  \n",
       "3                   testing!!!  testing!!!            \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('blogtext.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R6rlYDZEtWUH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 681284 entries, 0 to 681283\n",
      "Data columns (total 7 columns):\n",
      "id        681284 non-null int64\n",
      "gender    681284 non-null object\n",
      "age       681284 non-null int64\n",
      "topic     681284 non-null object\n",
      "sign      681284 non-null object\n",
      "date      681284 non-null object\n",
      "text      681284 non-null object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 36.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_df=df.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 7 columns):\n",
      "id        5000 non-null int64\n",
      "gender    5000 non-null object\n",
      "age       5000 non-null int64\n",
      "topic     5000 non-null object\n",
      "sign      5000 non-null object\n",
      "date      5000 non-null object\n",
      "text      5000 non-null object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 273.5+ KB\n"
     ]
    }
   ],
   "source": [
    "blog_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "poMI2itQtXyc"
   },
   "source": [
    "# Preprocess rows of the “text” column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZNxR-m2mt8Jk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>text_wo_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "      <td>Info has been found  100 pages and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "      <td>These are the team members   Drewes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "      <td>testing  testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "      <td>Thanks to Yahoos Toolbar I can no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  \\\n",
       "0             Info has been found (+/- 100 pages,...   \n",
       "1             These are the team members:   Drewe...   \n",
       "2             In het kader van kernfusie op aarde...   \n",
       "3                   testing!!!  testing!!!             \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...   \n",
       "\n",
       "                                       text_wo_punct  \n",
       "0             Info has been found  100 pages and ...  \n",
       "1             These are the team members   Drewes...  \n",
       "2             In het kader van kernfusie op aarde...  \n",
       "3                         testing  testing            \n",
       "4               Thanks to Yahoos Toolbar I can no...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REMOVE_PUNCT = string.punctuation\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', REMOVE_PUNCT))\n",
    "\n",
    "blog_df[\"text_wo_punct\"] = blog_df[\"text\"].apply(lambda text: remove_punctuation(text))\n",
    "blog_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k2iDgwZZt8MY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>text_wo_punct</th>\n",
       "      <th>text_wo_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "      <td>Info has been found  100 pages and ...</td>\n",
       "      <td>Info found 100 pages 45 MB pdf files Now wait ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "      <td>These are the team members   Drewes...</td>\n",
       "      <td>These team members Drewes van der Laag urlLink...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "      <td>In het kader van kernfusie op aarde MAAK JE EI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "      <td>testing  testing</td>\n",
       "      <td>testing testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "      <td>Thanks to Yahoos Toolbar I can no...</td>\n",
       "      <td>Thanks Yahoos Toolbar I capture URLs popupswhi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  \\\n",
       "0             Info has been found (+/- 100 pages,...   \n",
       "1             These are the team members:   Drewe...   \n",
       "2             In het kader van kernfusie op aarde...   \n",
       "3                   testing!!!  testing!!!             \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...   \n",
       "\n",
       "                                       text_wo_punct  \\\n",
       "0             Info has been found  100 pages and ...   \n",
       "1             These are the team members   Drewes...   \n",
       "2             In het kader van kernfusie op aarde...   \n",
       "3                         testing  testing             \n",
       "4               Thanks to Yahoos Toolbar I can no...   \n",
       "\n",
       "                                        text_wo_stop  \n",
       "0  Info found 100 pages 45 MB pdf files Now wait ...  \n",
       "1  These team members Drewes van der Laag urlLink...  \n",
       "2  In het kader van kernfusie op aarde MAAK JE EI...  \n",
       "3                                    testing testing  \n",
       "4  Thanks Yahoos Toolbar I capture URLs popupswhi...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "blog_df[\"text_wo_stop\"] = blog_df[\"text_wo_punct\"].apply(lambda text: remove_stopwords(text))\n",
    "blog_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FzQh6CqHt7_1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>text_wo_punct</th>\n",
       "      <th>text_wo_stop</th>\n",
       "      <th>text_wo_stopfreq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "      <td>Info has been found  100 pages and ...</td>\n",
       "      <td>Info found 100 pages 45 MB pdf files Now wait ...</td>\n",
       "      <td>Info found 100 pages 45 MB pdf files Now wait ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "      <td>These are the team members   Drewes...</td>\n",
       "      <td>These team members Drewes van der Laag urlLink...</td>\n",
       "      <td>These team members Drewes van der Laag urlLink...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "      <td>In het kader van kernfusie op aarde MAAK JE EI...</td>\n",
       "      <td>In het kader van kernfusie op aarde MAAK JE EI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "      <td>testing  testing</td>\n",
       "      <td>testing testing</td>\n",
       "      <td>testing testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "      <td>Thanks to Yahoos Toolbar I can no...</td>\n",
       "      <td>Thanks Yahoos Toolbar I capture URLs popupswhi...</td>\n",
       "      <td>Thanks Yahoos Toolbar I capture URLs popupswhi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  \\\n",
       "0             Info has been found (+/- 100 pages,...   \n",
       "1             These are the team members:   Drewe...   \n",
       "2             In het kader van kernfusie op aarde...   \n",
       "3                   testing!!!  testing!!!             \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...   \n",
       "\n",
       "                                       text_wo_punct  \\\n",
       "0             Info has been found  100 pages and ...   \n",
       "1             These are the team members   Drewes...   \n",
       "2             In het kader van kernfusie op aarde...   \n",
       "3                         testing  testing             \n",
       "4               Thanks to Yahoos Toolbar I can no...   \n",
       "\n",
       "                                        text_wo_stop  \\\n",
       "0  Info found 100 pages 45 MB pdf files Now wait ...   \n",
       "1  These team members Drewes van der Laag urlLink...   \n",
       "2  In het kader van kernfusie op aarde MAAK JE EI...   \n",
       "3                                    testing testing   \n",
       "4  Thanks Yahoos Toolbar I capture URLs popupswhi...   \n",
       "\n",
       "                                    text_wo_stopfreq  \n",
       "0  Info found 100 pages 45 MB pdf files Now wait ...  \n",
       "1  These team members Drewes van der Laag urlLink...  \n",
       "2  In het kader van kernfusie op aarde MAAK JE EI...  \n",
       "3                                    testing testing  \n",
       "4  Thanks Yahoos Toolbar I capture URLs popupswhi...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = Counter()\n",
    "FREQWORDS = set([w for (w, wc) in cnt.most_common(10)])\n",
    "def remove_freqwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in FREQWORDS])\n",
    "blog_df[\"text_wo_stopfreq\"] = blog_df[\"text_wo_stop\"].apply(lambda text: remove_freqwords(text))\n",
    "blog_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "GFrt5E3auQlM",
    "outputId": "05f9fcd6-6e21-408d-82d7-e86b700cba08"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>text_wo_stopfreq</th>\n",
       "      <th>text_wo_stopfreqrare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "      <td>Info found 100 pages 45 MB pdf files Now wait ...</td>\n",
       "      <td>Info found 100 pages 45 MB pdf files Now wait ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "      <td>These team members Drewes van der Laag urlLink...</td>\n",
       "      <td>These team members Drewes van der Laag urlLink...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "      <td>In het kader van kernfusie op aarde MAAK JE EI...</td>\n",
       "      <td>In het kader van kernfusie op aarde MAAK JE EI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "      <td>testing testing</td>\n",
       "      <td>testing testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "      <td>Thanks Yahoos Toolbar I capture URLs popupswhi...</td>\n",
       "      <td>Thanks Yahoos Toolbar I capture URLs popupswhi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  \\\n",
       "0             Info has been found (+/- 100 pages,...   \n",
       "1             These are the team members:   Drewe...   \n",
       "2             In het kader van kernfusie op aarde...   \n",
       "3                   testing!!!  testing!!!             \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...   \n",
       "\n",
       "                                    text_wo_stopfreq  \\\n",
       "0  Info found 100 pages 45 MB pdf files Now wait ...   \n",
       "1  These team members Drewes van der Laag urlLink...   \n",
       "2  In het kader van kernfusie op aarde MAAK JE EI...   \n",
       "3                                    testing testing   \n",
       "4  Thanks Yahoos Toolbar I capture URLs popupswhi...   \n",
       "\n",
       "                                text_wo_stopfreqrare  \n",
       "0  Info found 100 pages 45 MB pdf files Now wait ...  \n",
       "1  These team members Drewes van der Laag urlLink...  \n",
       "2  In het kader van kernfusie op aarde MAAK JE EI...  \n",
       "3                                    testing testing  \n",
       "4  Thanks Yahoos Toolbar I capture URLs popupswhi...  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_df.drop([\"text_wo_punct\", \"text_wo_stop\"], axis=1, inplace=True)\n",
    "n_rare_words = 10\n",
    "RAREWORDS = set([w for (w, wc) in cnt.most_common()[:-n_rare_words-1:-1]])\n",
    "def remove_rarewords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in RAREWORDS])\n",
    "blog_df[\"text_wo_stopfreqrare\"] = blog_df[\"text_wo_stopfreq\"].apply(lambda text: remove_rarewords(text))\n",
    "blog_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sJvg2RzEuQs4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>text_wo_stopfreq</th>\n",
       "      <th>text_wo_stopfreqrare</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "      <td>Info found 100 pages 45 MB pdf files Now wait ...</td>\n",
       "      <td>Info found 100 pages 45 MB pdf files Now wait ...</td>\n",
       "      <td>Info found 100 page 45 MB pdf file Now wait un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "      <td>These team members Drewes van der Laag urlLink...</td>\n",
       "      <td>These team members Drewes van der Laag urlLink...</td>\n",
       "      <td>These team member Drewes van der Laag urlLink ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "      <td>In het kader van kernfusie op aarde MAAK JE EI...</td>\n",
       "      <td>In het kader van kernfusie op aarde MAAK JE EI...</td>\n",
       "      <td>In het kader van kernfusie op aarde MAAK JE EI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "      <td>testing testing</td>\n",
       "      <td>testing testing</td>\n",
       "      <td>testing testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "      <td>Thanks Yahoos Toolbar I capture URLs popupswhi...</td>\n",
       "      <td>Thanks Yahoos Toolbar I capture URLs popupswhi...</td>\n",
       "      <td>Thanks Yahoos Toolbar I capture URLs popupswhi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  \\\n",
       "0             Info has been found (+/- 100 pages,...   \n",
       "1             These are the team members:   Drewe...   \n",
       "2             In het kader van kernfusie op aarde...   \n",
       "3                   testing!!!  testing!!!             \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...   \n",
       "\n",
       "                                    text_wo_stopfreq  \\\n",
       "0  Info found 100 pages 45 MB pdf files Now wait ...   \n",
       "1  These team members Drewes van der Laag urlLink...   \n",
       "2  In het kader van kernfusie op aarde MAAK JE EI...   \n",
       "3                                    testing testing   \n",
       "4  Thanks Yahoos Toolbar I capture URLs popupswhi...   \n",
       "\n",
       "                                text_wo_stopfreqrare  \\\n",
       "0  Info found 100 pages 45 MB pdf files Now wait ...   \n",
       "1  These team members Drewes van der Laag urlLink...   \n",
       "2  In het kader van kernfusie op aarde MAAK JE EI...   \n",
       "3                                    testing testing   \n",
       "4  Thanks Yahoos Toolbar I capture URLs popupswhi...   \n",
       "\n",
       "                                     text_lemmatized  \n",
       "0  Info found 100 page 45 MB pdf file Now wait un...  \n",
       "1  These team member Drewes van der Laag urlLink ...  \n",
       "2  In het kader van kernfusie op aarde MAAK JE EI...  \n",
       "3                                    testing testing  \n",
       "4  Thanks Yahoos Toolbar I capture URLs popupswhi...  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "def lemmatize_words(text):\n",
    "    return \" \".join([lem.lemmatize(word) for word in text.split()])\n",
    "blog_df[\"text_lemmatized\"] = blog_df[\"text_wo_stopfreqrare\"].apply(lambda text: lemmatize_words(text))\n",
    "blog_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yWHCKqBwuQzS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of            id  gender  age              topic      sign            date  \\\n",
       "0     2059027    male   15            Student       Leo     14,May,2004   \n",
       "1     2059027    male   15            Student       Leo     13,May,2004   \n",
       "2     2059027    male   15            Student       Leo     12,May,2004   \n",
       "3     2059027    male   15            Student       Leo     12,May,2004   \n",
       "4     3581210    male   33  InvestmentBanking  Aquarius    11,June,2004   \n",
       "5     3581210    male   33  InvestmentBanking  Aquarius    10,June,2004   \n",
       "6     3581210    male   33  InvestmentBanking  Aquarius    10,June,2004   \n",
       "7     3581210    male   33  InvestmentBanking  Aquarius    10,June,2004   \n",
       "8     3581210    male   33  InvestmentBanking  Aquarius    10,June,2004   \n",
       "9     3581210    male   33  InvestmentBanking  Aquarius    09,June,2004   \n",
       "10    3581210    male   33  InvestmentBanking  Aquarius    09,June,2004   \n",
       "11    3581210    male   33  InvestmentBanking  Aquarius    09,June,2004   \n",
       "12    3581210    male   33  InvestmentBanking  Aquarius    09,June,2004   \n",
       "13    3581210    male   33  InvestmentBanking  Aquarius    09,June,2004   \n",
       "14    3581210    male   33  InvestmentBanking  Aquarius    09,June,2004   \n",
       "15    3581210    male   33  InvestmentBanking  Aquarius    09,June,2004   \n",
       "16    3581210    male   33  InvestmentBanking  Aquarius    09,June,2004   \n",
       "17    3581210    male   33  InvestmentBanking  Aquarius    18,June,2004   \n",
       "18    3581210    male   33  InvestmentBanking  Aquarius    17,June,2004   \n",
       "19    3581210    male   33  InvestmentBanking  Aquarius    16,June,2004   \n",
       "20    3581210    male   33  InvestmentBanking  Aquarius    15,June,2004   \n",
       "21    3581210    male   33  InvestmentBanking  Aquarius    14,June,2004   \n",
       "22    3581210    male   33  InvestmentBanking  Aquarius    13,June,2004   \n",
       "23    3581210    male   33  InvestmentBanking  Aquarius    23,June,2004   \n",
       "24    3581210    male   33  InvestmentBanking  Aquarius    22,June,2004   \n",
       "25    3581210    male   33  InvestmentBanking  Aquarius    20,June,2004   \n",
       "26    3581210    male   33  InvestmentBanking  Aquarius    02,July,2004   \n",
       "27    3581210    male   33  InvestmentBanking  Aquarius    01,July,2004   \n",
       "28    3581210    male   33  InvestmentBanking  Aquarius    01,July,2004   \n",
       "29    3581210    male   33  InvestmentBanking  Aquarius    30,June,2004   \n",
       "...       ...     ...  ...                ...       ...             ...   \n",
       "4970  1103575  female   17             indUnk   Scorpio    06,July,2003   \n",
       "4971  1103575  female   17             indUnk   Scorpio    06,July,2003   \n",
       "4972  1103575  female   17             indUnk   Scorpio    03,July,2003   \n",
       "4973  1103575  female   17             indUnk   Scorpio    03,July,2003   \n",
       "4974  1103575  female   17             indUnk   Scorpio    03,July,2003   \n",
       "4975  1103575  female   17             indUnk   Scorpio    02,July,2003   \n",
       "4976  1103575  female   17             indUnk   Scorpio    01,July,2003   \n",
       "4977  1103575  female   17             indUnk   Scorpio  31,August,2003   \n",
       "4978  1103575  female   17             indUnk   Scorpio  30,August,2003   \n",
       "4979  1103575  female   17             indUnk   Scorpio  30,August,2003   \n",
       "4980  1103575  female   17             indUnk   Scorpio  29,August,2003   \n",
       "4981  1103575  female   17             indUnk   Scorpio  29,August,2003   \n",
       "4982  1103575  female   17             indUnk   Scorpio  29,August,2003   \n",
       "4983  1103575  female   17             indUnk   Scorpio  29,August,2003   \n",
       "4984  1103575  female   17             indUnk   Scorpio  29,August,2003   \n",
       "4985  1103575  female   17             indUnk   Scorpio  29,August,2003   \n",
       "4986  1103575  female   17             indUnk   Scorpio  29,August,2003   \n",
       "4987  1103575  female   17             indUnk   Scorpio  28,August,2003   \n",
       "4988  1103575  female   17             indUnk   Scorpio  28,August,2003   \n",
       "4989  1103575  female   17             indUnk   Scorpio  28,August,2003   \n",
       "4990  1103575  female   17             indUnk   Scorpio  28,August,2003   \n",
       "4991  1103575  female   17             indUnk   Scorpio  28,August,2003   \n",
       "4992  1103575  female   17             indUnk   Scorpio  28,August,2003   \n",
       "4993  1103575  female   17             indUnk   Scorpio  27,August,2003   \n",
       "4994  1103575  female   17             indUnk   Scorpio  27,August,2003   \n",
       "4995  1103575  female   17             indUnk   Scorpio  27,August,2003   \n",
       "4996  1103575  female   17             indUnk   Scorpio  27,August,2003   \n",
       "4997  1103575  female   17             indUnk   Scorpio  27,August,2003   \n",
       "4998  1103575  female   17             indUnk   Scorpio  26,August,2003   \n",
       "4999  1103575  female   17             indUnk   Scorpio  26,August,2003   \n",
       "\n",
       "                                                   text  \\\n",
       "0                Info has been found (+/- 100 pages,...   \n",
       "1                These are the team members:   Drewe...   \n",
       "2                In het kader van kernfusie op aarde...   \n",
       "3                      testing!!!  testing!!!             \n",
       "4                  Thanks to Yahoo!'s Toolbar I can ...   \n",
       "5                  I had an interesting conversation...   \n",
       "6                  Somehow Coca-Cola has a way of su...   \n",
       "7                  If anything, Korea is a country o...   \n",
       "8                  Take a read of this news article ...   \n",
       "9                  I surf the English news sites a l...   \n",
       "10                 Ah, the Korean language...it look...   \n",
       "11                 If you click on my profile you'll...   \n",
       "12                 Last night was pretty fun...mostl...   \n",
       "13                 There is so much that is differen...   \n",
       "14                  urlLink    Here it is, the super...   \n",
       "15                 One thing I love about Seoul (and...   \n",
       "16                  urlLink    Wonderful oh-gyup-sal...   \n",
       "17                 Here is the latest from the Korea...   \n",
       "18                 Well, I stand corrected, again.  ...   \n",
       "19                 So I've been in Vancouver a few d...   \n",
       "20                 Whenever I see a pregnant Korean ...   \n",
       "21                 My wife posed a strange question ...   \n",
       "22                 As readers will know, my favorite...   \n",
       "23                 When I was in Seoul these last fe...   \n",
       "24                 You may have noticed a new featur...   \n",
       "25                 Korea, especially Seoul, is prett...   \n",
       "26                 It seems everything is not all th...   \n",
       "27                 This may be a long blog...got a l...   \n",
       "28                 I've always thought of Seoul's  u...   \n",
       "29                 Big cities are famous for being e...   \n",
       "...                                                 ...   \n",
       "4970         mm...  I was going to rant about time/c...   \n",
       "4971         So, I guess its kind of like this... I ...   \n",
       "4972         this shade of red looks more and more l...   \n",
       "4973         ...look at me... teaching myself html.....   \n",
       "4974         My name is Rachel.  {duh, we already kn...   \n",
       "4975         Another depressing song... I don't know...   \n",
       "4976         I've been falling to pieces for the pas...   \n",
       "4977         I'm suffocating. My lungs are bursting....   \n",
       "4978         peaches are the nectar of the gods.  mm...   \n",
       "4979         AHHH. I need a pillow to scream into. o...   \n",
       "4980           Young.  Really young.  I'd say anywhe...   \n",
       "4981                                that's Sama...        \n",
       "4982                                                      \n",
       "4983                                                      \n",
       "4984           this one looks kinda cool squished li...   \n",
       "4985           yay for uploading my pics on to angel...   \n",
       "4986         Ok, so this is the last time today, I p...   \n",
       "4987         oh, and I forgot...  last night at cant...   \n",
       "4988         So, I got a new commenting host... I di...   \n",
       "4989         Last night was NOT a good night. {end o...   \n",
       "4990         Sometimes, I swear this song is about m...   \n",
       "4991         so much for sleeping...  I know what ti...   \n",
       "4992         I am: a miserable failure incredibly ir...   \n",
       "4993         hey I've had almost 300 hits... WHO ARE...   \n",
       "4994         This is that Sylvia Plath poem I was ta...   \n",
       "4995         So... I had another one of those dreams...   \n",
       "4996         mmm... strawberry tea for breakfast. To...   \n",
       "4997         Yay for a new layout!!  Yeah, I know, I...   \n",
       "4998         Ok, so I lied... Fed up isn't playing F...   \n",
       "4999         well, today I went to church and talked...   \n",
       "\n",
       "                                       text_wo_stopfreq  \\\n",
       "0     Info found 100 pages 45 MB pdf files Now wait ...   \n",
       "1     These team members Drewes van der Laag urlLink...   \n",
       "2     In het kader van kernfusie op aarde MAAK JE EI...   \n",
       "3                                       testing testing   \n",
       "4     Thanks Yahoos Toolbar I capture URLs popupswhi...   \n",
       "5     I interesting conversation Dad morning We talk...   \n",
       "6     Somehow CocaCola way summing things well In ea...   \n",
       "7     If anything Korea country extremes Everything ...   \n",
       "8     Take read news article urlLink JoongAng Ilbo N...   \n",
       "9     I surf English news sites lot looking tidbits ...   \n",
       "10    Ah Korean languageit looks difficult first fig...   \n",
       "11    If click profile youll make notsostartling dis...   \n",
       "12    Last night pretty funmostly company I kept I r...   \n",
       "13    There much different anything Ive ever seen we...   \n",
       "14    urlLink Here superfantastic phonebox Today gre...   \n",
       "15    One thing I love Seoul I mean Korea generalI h...   \n",
       "16    urlLink Wonderful ohgyupsal favorite pork rest...   \n",
       "17    Here latest Korean rumor mill made way Coquitl...   \n",
       "18    Well I stand corrected Yesterday I blogged Coq...   \n",
       "19    So Ive Vancouver days nowin Coquitlam actually...   \n",
       "20    Whenever I see pregnant Korean lady I really f...   \n",
       "21    My wife posed strange question tonight Apparen...   \n",
       "22    As readers know favorite airline Singapore Air...   \n",
       "23    When I Seoul last months I thought wife kinda ...   \n",
       "24    You may noticed new feature blogits blog email...   \n",
       "25    Korea especially Seoul pretty cool Canada espe...   \n",
       "26    It seems everything smooth Seoul concerning re...   \n",
       "27    This may long bloggot lot thoughts going head ...   \n",
       "28    Ive always thought Seouls urlLink subways real...   \n",
       "29    Big cities famous expensive places live others...   \n",
       "...                                                 ...   \n",
       "4970  mm I going rant timeclockswatches like says so...   \n",
       "4971  So I guess kind like I already told Ive fallen...   \n",
       "4972  shade red looks like blood doesnt matter doesn...   \n",
       "4973  look teaching html well I suppose halfway dece...   \n",
       "4974  My name Rachel duh already knew rachel hebrew ...   \n",
       "4975  Another depressing song I dont know I like I s...   \n",
       "4976  Ive falling pieces past several months I think...   \n",
       "4977  Im suffocating My lungs bursting If hit I woul...   \n",
       "4978  peaches nectar gods mmmmmmmmm Sometimes Im lay...   \n",
       "4979  AHHH I need pillow scream oh book Im reading g...   \n",
       "4980  Young Really young Id say anywhere 1535 But yo...   \n",
       "4981                                         thats Sama   \n",
       "4982                                                      \n",
       "4983                                                      \n",
       "4984                 one looks kinda cool squished like   \n",
       "4985  yay uploading pics angelfire putting blog exce...   \n",
       "4986  Ok last time today I promise Im really REALLY ...   \n",
       "4987  oh I forgot last night cantor practice I consi...   \n",
       "4988  So I got new commenting host I didnt like old ...   \n",
       "4989  Last night NOT good night end story Today inte...   \n",
       "4990  Sometimes I swear song 3am Matchbox Twenty say...   \n",
       "4991  much sleeping I know time I know time used I t...   \n",
       "4992  I miserable failure incredibly irresponsible l...   \n",
       "4993  hey Ive almost 300 hits WHO ARE ALL OF YOU PEOPLE   \n",
       "4994  This Sylvia Plath poem I talking Tulips Sylvia...   \n",
       "4995  So I another one dreams last night except time...   \n",
       "4996  mmm strawberry tea breakfast Tomorrow I think ...   \n",
       "4997  Yay new layout Yeah I know I need get complica...   \n",
       "4998  Ok I lied Fed isnt playing Friday night Its Th...   \n",
       "4999  well today I went church talked music director...   \n",
       "\n",
       "                                   text_wo_stopfreqrare  \\\n",
       "0     Info found 100 pages 45 MB pdf files Now wait ...   \n",
       "1     These team members Drewes van der Laag urlLink...   \n",
       "2     In het kader van kernfusie op aarde MAAK JE EI...   \n",
       "3                                       testing testing   \n",
       "4     Thanks Yahoos Toolbar I capture URLs popupswhi...   \n",
       "5     I interesting conversation Dad morning We talk...   \n",
       "6     Somehow CocaCola way summing things well In ea...   \n",
       "7     If anything Korea country extremes Everything ...   \n",
       "8     Take read news article urlLink JoongAng Ilbo N...   \n",
       "9     I surf English news sites lot looking tidbits ...   \n",
       "10    Ah Korean languageit looks difficult first fig...   \n",
       "11    If click profile youll make notsostartling dis...   \n",
       "12    Last night pretty funmostly company I kept I r...   \n",
       "13    There much different anything Ive ever seen we...   \n",
       "14    urlLink Here superfantastic phonebox Today gre...   \n",
       "15    One thing I love Seoul I mean Korea generalI h...   \n",
       "16    urlLink Wonderful ohgyupsal favorite pork rest...   \n",
       "17    Here latest Korean rumor mill made way Coquitl...   \n",
       "18    Well I stand corrected Yesterday I blogged Coq...   \n",
       "19    So Ive Vancouver days nowin Coquitlam actually...   \n",
       "20    Whenever I see pregnant Korean lady I really f...   \n",
       "21    My wife posed strange question tonight Apparen...   \n",
       "22    As readers know favorite airline Singapore Air...   \n",
       "23    When I Seoul last months I thought wife kinda ...   \n",
       "24    You may noticed new feature blogits blog email...   \n",
       "25    Korea especially Seoul pretty cool Canada espe...   \n",
       "26    It seems everything smooth Seoul concerning re...   \n",
       "27    This may long bloggot lot thoughts going head ...   \n",
       "28    Ive always thought Seouls urlLink subways real...   \n",
       "29    Big cities famous expensive places live others...   \n",
       "...                                                 ...   \n",
       "4970  mm I going rant timeclockswatches like says so...   \n",
       "4971  So I guess kind like I already told Ive fallen...   \n",
       "4972  shade red looks like blood doesnt matter doesn...   \n",
       "4973  look teaching html well I suppose halfway dece...   \n",
       "4974  My name Rachel duh already knew rachel hebrew ...   \n",
       "4975  Another depressing song I dont know I like I s...   \n",
       "4976  Ive falling pieces past several months I think...   \n",
       "4977  Im suffocating My lungs bursting If hit I woul...   \n",
       "4978  peaches nectar gods mmmmmmmmm Sometimes Im lay...   \n",
       "4979  AHHH I need pillow scream oh book Im reading g...   \n",
       "4980  Young Really young Id say anywhere 1535 But yo...   \n",
       "4981                                         thats Sama   \n",
       "4982                                                      \n",
       "4983                                                      \n",
       "4984                 one looks kinda cool squished like   \n",
       "4985  yay uploading pics angelfire putting blog exce...   \n",
       "4986  Ok last time today I promise Im really REALLY ...   \n",
       "4987  oh I forgot last night cantor practice I consi...   \n",
       "4988  So I got new commenting host I didnt like old ...   \n",
       "4989  Last night NOT good night end story Today inte...   \n",
       "4990  Sometimes I swear song 3am Matchbox Twenty say...   \n",
       "4991  much sleeping I know time I know time used I t...   \n",
       "4992  I miserable failure incredibly irresponsible l...   \n",
       "4993  hey Ive almost 300 hits WHO ARE ALL OF YOU PEOPLE   \n",
       "4994  This Sylvia Plath poem I talking Tulips Sylvia...   \n",
       "4995  So I another one dreams last night except time...   \n",
       "4996  mmm strawberry tea breakfast Tomorrow I think ...   \n",
       "4997  Yay new layout Yeah I know I need get complica...   \n",
       "4998  Ok I lied Fed isnt playing Friday night Its Th...   \n",
       "4999  well today I went church talked music director...   \n",
       "\n",
       "                                        text_lemmatized  \\\n",
       "0     Info found 100 page 45 MB pdf file Now wait un...   \n",
       "1     These team member Drewes van der Laag urlLink ...   \n",
       "2     In het kader van kernfusie op aarde MAAK JE EI...   \n",
       "3                                       testing testing   \n",
       "4     Thanks Yahoos Toolbar I capture URLs popupswhi...   \n",
       "5     I interesting conversation Dad morning We talk...   \n",
       "6     Somehow CocaCola way summing thing well In ear...   \n",
       "7     If anything Korea country extreme Everything s...   \n",
       "8     Take read news article urlLink JoongAng Ilbo N...   \n",
       "9     I surf English news site lot looking tidbit Ko...   \n",
       "10    Ah Korean languageit look difficult first figu...   \n",
       "11    If click profile youll make notsostartling dis...   \n",
       "12    Last night pretty funmostly company I kept I r...   \n",
       "13    There much different anything Ive ever seen we...   \n",
       "14    urlLink Here superfantastic phonebox Today gre...   \n",
       "15    One thing I love Seoul I mean Korea generalI h...   \n",
       "16    urlLink Wonderful ohgyupsal favorite pork rest...   \n",
       "17    Here latest Korean rumor mill made way Coquitl...   \n",
       "18    Well I stand corrected Yesterday I blogged Coq...   \n",
       "19    So Ive Vancouver day nowin Coquitlam actually ...   \n",
       "20    Whenever I see pregnant Korean lady I really f...   \n",
       "21    My wife posed strange question tonight Apparen...   \n",
       "22    As reader know favorite airline Singapore Air ...   \n",
       "23    When I Seoul last month I thought wife kinda e...   \n",
       "24    You may noticed new feature blogits blog email...   \n",
       "25    Korea especially Seoul pretty cool Canada espe...   \n",
       "26    It seems everything smooth Seoul concerning re...   \n",
       "27    This may long bloggot lot thought going head l...   \n",
       "28    Ive always thought Seouls urlLink subway real ...   \n",
       "29    Big city famous expensive place live others co...   \n",
       "...                                                 ...   \n",
       "4970  mm I going rant timeclockswatches like say soc...   \n",
       "4971  So I guess kind like I already told Ive fallen...   \n",
       "4972  shade red look like blood doesnt matter doesnt...   \n",
       "4973  look teaching html well I suppose halfway dece...   \n",
       "4974  My name Rachel duh already knew rachel hebrew ...   \n",
       "4975  Another depressing song I dont know I like I s...   \n",
       "4976  Ive falling piece past several month I think I...   \n",
       "4977  Im suffocating My lung bursting If hit I would...   \n",
       "4978  peach nectar god mmmmmmmmm Sometimes Im laying...   \n",
       "4979  AHHH I need pillow scream oh book Im reading g...   \n",
       "4980  Young Really young Id say anywhere 1535 But yo...   \n",
       "4981                                         thats Sama   \n",
       "4982                                                      \n",
       "4983                                                      \n",
       "4984                  one look kinda cool squished like   \n",
       "4985  yay uploading pic angelfire putting blog excep...   \n",
       "4986  Ok last time today I promise Im really REALLY ...   \n",
       "4987  oh I forgot last night cantor practice I consi...   \n",
       "4988  So I got new commenting host I didnt like old ...   \n",
       "4989  Last night NOT good night end story Today inte...   \n",
       "4990  Sometimes I swear song 3am Matchbox Twenty say...   \n",
       "4991  much sleeping I know time I know time used I t...   \n",
       "4992  I miserable failure incredibly irresponsible l...   \n",
       "4993   hey Ive almost 300 hit WHO ARE ALL OF YOU PEOPLE   \n",
       "4994  This Sylvia Plath poem I talking Tulips Sylvia...   \n",
       "4995  So I another one dream last night except time ...   \n",
       "4996  mmm strawberry tea breakfast Tomorrow I think ...   \n",
       "4997  Yay new layout Yeah I know I need get complica...   \n",
       "4998  Ok I lied Fed isnt playing Friday night Its Th...   \n",
       "4999  well today I went church talked music director...   \n",
       "\n",
       "                                      text_preprocessed  \n",
       "0     info found 100 page 45 MB pdf file now wait un...  \n",
       "1     these team member drew van der laag urllink ma...  \n",
       "2     In het kader van kernfusi op aard maak JE eige...  \n",
       "3                                             test test  \n",
       "4     thank yahoo toolbar I captur url popupswhich m...  \n",
       "5     I interest convers dad morn We talk korean put...  \n",
       "6     somehow cocacola way sum thing well In earli 1...  \n",
       "7     If anyth korea countri extrem everyth seem fad...  \n",
       "8     take read news articl urllink joongang ilbo no...  \n",
       "9     I surf english news site lot look tidbit korea...  \n",
       "10    Ah korean languageit look difficult first figu...  \n",
       "11    If click profil youll make notsostartl discove...  \n",
       "12    last night pretti funmostli compani I kept I r...  \n",
       "13    there much differ anyth ive ever seen well I h...  \n",
       "14    urllink here superfantast phonebox today great...  \n",
       "15    one thing I love seoul I mean korea generali h...  \n",
       "16    urllink wonder ohgyups favorit pork restaur it...  \n",
       "17    here latest korean rumor mill made way coquitl...  \n",
       "18    well I stand correct yesterday I blog coquitla...  \n",
       "19    So ive vancouv day nowin coquitlam actual it r...  \n",
       "20    whenev I see pregnant korean ladi I realli fee...  \n",
       "21    My wife pose strang question tonight appar new...  \n",
       "22    As reader know favorit airlin singapor air sai...  \n",
       "23    when I seoul last month I thought wife kinda e...  \n",
       "24    you may notic new featur blogit blog email not...  \n",
       "25    korea especi seoul pretti cool canada especi v...  \n",
       "26    It seem everyth smooth seoul concern recent ch...  \n",
       "27    thi may long bloggot lot thought go head last ...  \n",
       "28    ive alway thought seoul urllink subway real jo...  \n",
       "29    big citi famou expens place live other cours h...  \n",
       "...                                                 ...  \n",
       "4970  mm I go rant timeclockswatch like say societi ...  \n",
       "4971  So I guess kind like I alreadi told ive fallen...  \n",
       "4972  shade red look like blood doesnt matter doesnt...  \n",
       "4973  look teach html well I suppos halfway decent isnt  \n",
       "4974  My name rachel duh alreadi knew rachel hebrew ...  \n",
       "4975  anoth depress song I dont know I like I suppos...  \n",
       "4976  ive fall piec past sever month I think Im fina...  \n",
       "4977  Im suffoc My lung burst If hit I would pop lik...  \n",
       "4978  peach nectar god mmmmmmmmm sometim Im lay awak...  \n",
       "4979  ahhh I need pillow scream oh book Im read guy ...  \n",
       "4980  young realli young Id say anywher 1535 but you...  \n",
       "4981                                          that sama  \n",
       "4982                                                     \n",
       "4983                                                     \n",
       "4984                    one look kinda cool squish like  \n",
       "4985  yay upload pic angelfir put blog except theyr ...  \n",
       "4986  Ok last time today I promis Im realli realli g...  \n",
       "4987  oh I forgot last night cantor practic I consis...  \n",
       "4988  So I got new comment host I didnt like old one...  \n",
       "4989  last night not good night end stori today inte...  \n",
       "4990  sometim I swear song 3am matchbox twenti say c...  \n",
       "4991  much sleep I know time I know time use I think...  \n",
       "4992  I miser failur incred irrespons late never goo...  \n",
       "4993    hey ive almost 300 hit who are all OF you peopl  \n",
       "4994  thi sylvia plath poem I talk tulip sylvia plat...  \n",
       "4995  So I anoth one dream last night except time le...  \n",
       "4996  mmm strawberri tea breakfast tomorrow I think ...  \n",
       "4997  yay new layout yeah I know I need get complic ...  \n",
       "4998  Ok I lie fed isnt play friday night it the und...  \n",
       "4999  well today I went church talk music director t...  \n",
       "\n",
       "[5000 rows x 11 columns]>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([stem.stem(word) for word in text.split()])\n",
    "blog_df[\"text_preprocessed\"] = blog_df[\"text_lemmatized\"].apply(lambda text: stem_words(text))\n",
    "blog_df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sYHYLQonuQrC",
    "outputId": "c235b95c-aa6b-4e75-b8b4-03df068a239f"
   },
   "source": [
    "# As we want to make this into a multi-label classification problem, you are required to merge all the label columns together, so that we have all the labels together for a particular sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gMstdJueuada",
    "outputId": "6668049f-3866-4b09-b846-457909c40cd2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>text_wo_stopfreq</th>\n",
       "      <th>text_wo_stopfreqrare</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "      <td>Info found 100 pages 45 MB pdf files Now wait ...</td>\n",
       "      <td>Info found 100 pages 45 MB pdf files Now wait ...</td>\n",
       "      <td>Info found 100 page 45 MB pdf file Now wait un...</td>\n",
       "      <td>info found 100 page 45 MB pdf file now wait un...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "      <td>These team members Drewes van der Laag urlLink...</td>\n",
       "      <td>These team members Drewes van der Laag urlLink...</td>\n",
       "      <td>These team member Drewes van der Laag urlLink ...</td>\n",
       "      <td>these team member drew van der laag urllink ma...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "      <td>In het kader van kernfusie op aarde MAAK JE EI...</td>\n",
       "      <td>In het kader van kernfusie op aarde MAAK JE EI...</td>\n",
       "      <td>In het kader van kernfusie op aarde MAAK JE EI...</td>\n",
       "      <td>In het kader van kernfusi op aard maak JE eige...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "      <td>testing testing</td>\n",
       "      <td>testing testing</td>\n",
       "      <td>testing testing</td>\n",
       "      <td>test test</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "      <td>Thanks Yahoos Toolbar I capture URLs popupswhi...</td>\n",
       "      <td>Thanks Yahoos Toolbar I capture URLs popupswhi...</td>\n",
       "      <td>Thanks Yahoos Toolbar I capture URLs popupswhi...</td>\n",
       "      <td>thank yahoo toolbar I captur url popupswhich m...</td>\n",
       "      <td>[male, 33, InvestmentBanking, Aquarius]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  \\\n",
       "0             Info has been found (+/- 100 pages,...   \n",
       "1             These are the team members:   Drewe...   \n",
       "2             In het kader van kernfusie op aarde...   \n",
       "3                   testing!!!  testing!!!             \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...   \n",
       "\n",
       "                                    text_wo_stopfreq  \\\n",
       "0  Info found 100 pages 45 MB pdf files Now wait ...   \n",
       "1  These team members Drewes van der Laag urlLink...   \n",
       "2  In het kader van kernfusie op aarde MAAK JE EI...   \n",
       "3                                    testing testing   \n",
       "4  Thanks Yahoos Toolbar I capture URLs popupswhi...   \n",
       "\n",
       "                                text_wo_stopfreqrare  \\\n",
       "0  Info found 100 pages 45 MB pdf files Now wait ...   \n",
       "1  These team members Drewes van der Laag urlLink...   \n",
       "2  In het kader van kernfusie op aarde MAAK JE EI...   \n",
       "3                                    testing testing   \n",
       "4  Thanks Yahoos Toolbar I capture URLs popupswhi...   \n",
       "\n",
       "                                     text_lemmatized  \\\n",
       "0  Info found 100 page 45 MB pdf file Now wait un...   \n",
       "1  These team member Drewes van der Laag urlLink ...   \n",
       "2  In het kader van kernfusie op aarde MAAK JE EI...   \n",
       "3                                    testing testing   \n",
       "4  Thanks Yahoos Toolbar I capture URLs popupswhi...   \n",
       "\n",
       "                                   text_preprocessed  \\\n",
       "0  info found 100 page 45 MB pdf file now wait un...   \n",
       "1  these team member drew van der laag urllink ma...   \n",
       "2  In het kader van kernfusi op aard maak JE eige...   \n",
       "3                                          test test   \n",
       "4  thank yahoo toolbar I captur url popupswhich m...   \n",
       "\n",
       "                                    Labels  \n",
       "0                 [male, 15, Student, Leo]  \n",
       "1                 [male, 15, Student, Leo]  \n",
       "2                 [male, 15, Student, Leo]  \n",
       "3                 [male, 15, Student, Leo]  \n",
       "4  [male, 33, InvestmentBanking, Aquarius]  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_y = []\n",
    "\n",
    "for row in blog_df.iterrows():\n",
    "    row_labels = []\n",
    "    row_labels.append(str(row[1][1]))\n",
    "    row_labels.append(str(row[1][2]))\n",
    "    row_labels.append(str(row[1][3]))\n",
    "    row_labels.append(str(row[1][4]))\n",
    "    label_y.append(row_labels)\n",
    "\n",
    "blog_df['Labels'] = label_y\n",
    "blog_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dictionary to get the count of every label i.e. the key will be label name and value will be the total count of the label. Check below image for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'male': 3294, 'female': 1706}\n"
     ]
    }
   ],
   "source": [
    "gender = blog_df['gender'].value_counts().to_dict()\n",
    "print(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Technology': 2332, 'indUnk': 1381, 'Student': 569, 'Engineering': 119, 'Education': 118, 'BusinessServices': 87, 'Sports-Recreation': 75, 'InvestmentBanking': 70, 'Communications-Media': 61, 'Non-Profit': 47, 'Science': 33, 'Arts': 31, 'Internet': 20, 'Consulting': 16, 'Banking': 16, 'Automotive': 14, 'Religion': 4, 'Law': 3, 'Accounting': 2, 'Museums-Libraries': 2}\n"
     ]
    }
   ],
   "source": [
    "topics = blog_df['topic'].value_counts().to_dict()\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{35: 2307, 34: 540, 24: 353, 15: 339, 17: 331, 25: 268, 14: 170, 23: 137, 33: 101, 26: 96, 27: 86, 39: 79, 16: 67, 36: 60, 37: 19, 41: 14, 45: 14, 42: 9, 46: 7, 44: 3}\n"
     ]
    }
   ],
   "source": [
    "age = blog_df['age'].value_counts().to_dict()\n",
    "print(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>info found 100 page 45 MB pdf file now wait un...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>these team member drew van der laag urllink ma...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In het kader van kernfusi op aard maak JE eige...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test test</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thank yahoo toolbar I captur url popupswhich m...</td>\n",
       "      <td>[male, 33, InvestmentBanking, Aquarius]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text_preprocessed  \\\n",
       "0  info found 100 page 45 MB pdf file now wait un...   \n",
       "1  these team member drew van der laag urllink ma...   \n",
       "2  In het kader van kernfusi op aard maak JE eige...   \n",
       "3                                          test test   \n",
       "4  thank yahoo toolbar I captur url popupswhich m...   \n",
       "\n",
       "                                    Labels  \n",
       "0                 [male, 15, Student, Leo]  \n",
       "1                 [male, 15, Student, Leo]  \n",
       "2                 [male, 15, Student, Leo]  \n",
       "3                 [male, 15, Student, Leo]  \n",
       "4  [male, 33, InvestmentBanking, Aquarius]  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_df = blog_df[[\"text_preprocessed\", \"Labels\"]]\n",
    "blog_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate features and labels, and split the data into training and testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = blog_df['text_preprocessed']\n",
    "y = blog_df['Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "X_train = cnt_vectorizer.fit_transform(X_train)\n",
    "X_test = cnt_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " '000 peopl',\n",
       " '0000',\n",
       " '0000 blink',\n",
       " '001',\n",
       " '001 first',\n",
       " '002',\n",
       " '002 middl',\n",
       " '003',\n",
       " '003 last',\n",
       " '004',\n",
       " '004 nicknam',\n",
       " '005',\n",
       " '005 gender',\n",
       " '006',\n",
       " '006 age',\n",
       " '007',\n",
       " '007 birthday',\n",
       " '007 game',\n",
       " '007 jersey',\n",
       " '008',\n",
       " '008 height',\n",
       " '009',\n",
       " '009 hair',\n",
       " '01',\n",
       " '01 2003',\n",
       " '01 bett',\n",
       " '01 mean',\n",
       " '01 mind',\n",
       " '010',\n",
       " '010 eye',\n",
       " '010203',\n",
       " '010203 heheh',\n",
       " '011',\n",
       " '011 race',\n",
       " '012',\n",
       " '012 glass',\n",
       " '012 last',\n",
       " '01234',\n",
       " '01234 but',\n",
       " '013',\n",
       " '013 dodid',\n",
       " '014',\n",
       " '014 is',\n",
       " '015',\n",
       " '015 where',\n",
       " '016',\n",
       " '016 current',\n",
       " '017',\n",
       " '017 zodiac',\n",
       " '018',\n",
       " '018 how',\n",
       " '019',\n",
       " '019 nation',\n",
       " '02',\n",
       " '02 ad',\n",
       " '02 and',\n",
       " '02 britney',\n",
       " '02 face',\n",
       " '02 lott',\n",
       " '02 republican',\n",
       " '02 where',\n",
       " '020',\n",
       " '020 bad',\n",
       " '020031',\n",
       " '020031 pm',\n",
       " '021',\n",
       " '021 it',\n",
       " '021 pierc',\n",
       " '02182004',\n",
       " '02182004 urllink',\n",
       " '022',\n",
       " '022 pierc',\n",
       " '02232004',\n",
       " '023',\n",
       " '023 tattoo',\n",
       " '024',\n",
       " '024 tattoo',\n",
       " '025',\n",
       " '025 today',\n",
       " '025613',\n",
       " '025613 pm',\n",
       " '026',\n",
       " '026 main',\n",
       " '026 the',\n",
       " '027',\n",
       " '027 readi',\n",
       " '028',\n",
       " '028 mother',\n",
       " '029',\n",
       " '029 father',\n",
       " '03',\n",
       " '03 calvin',\n",
       " '03 januari',\n",
       " '03 know',\n",
       " '030',\n",
       " '030 steppar',\n",
       " '031',\n",
       " '031 brotherss',\n",
       " '03152004',\n",
       " '03152004 urllink',\n",
       " '032',\n",
       " '032 sisterss',\n",
       " '033',\n",
       " '033 favorit',\n",
       " '033100',\n",
       " '033100 pm',\n",
       " '034',\n",
       " '034 favorit',\n",
       " '035',\n",
       " '035 favorit',\n",
       " '036',\n",
       " '036 worst',\n",
       " '037',\n",
       " '037 best',\n",
       " '038',\n",
       " '038 do',\n",
       " '039',\n",
       " '039 doe',\n",
       " '04',\n",
       " '04 ad',\n",
       " '04 the',\n",
       " '040',\n",
       " '040 24hour',\n",
       " '040 do',\n",
       " '041',\n",
       " '041 what',\n",
       " '042',\n",
       " '042 what',\n",
       " '043',\n",
       " '043 are',\n",
       " '044',\n",
       " '044 did',\n",
       " '045',\n",
       " '045 current',\n",
       " '045090',\n",
       " '045090 usd',\n",
       " '046',\n",
       " '046 favorit',\n",
       " '047',\n",
       " '047 least',\n",
       " '048',\n",
       " '048 favorit',\n",
       " '049',\n",
       " '049 least',\n",
       " '05',\n",
       " '05 074658',\n",
       " '05 jul',\n",
       " '05 may',\n",
       " '050',\n",
       " '050 favorit',\n",
       " '051',\n",
       " '051 least',\n",
       " '051304',\n",
       " '051304 email',\n",
       " '052',\n",
       " '052 dodid',\n",
       " '05292004',\n",
       " '05292004 dreamtheaternet',\n",
       " '053',\n",
       " '053 play',\n",
       " '054',\n",
       " '054 dodid',\n",
       " '055',\n",
       " '055 arewer',\n",
       " '056',\n",
       " '056 favorit',\n",
       " '057',\n",
       " '057 favorit',\n",
       " '058',\n",
       " '058 least',\n",
       " '059',\n",
       " '059 least',\n",
       " '06',\n",
       " '06 091103',\n",
       " '06 100010',\n",
       " '06 112850',\n",
       " '06 121148',\n",
       " '06 sure',\n",
       " '060',\n",
       " '060 most',\n",
       " '060404',\n",
       " '060404 better',\n",
       " '061',\n",
       " '061 number',\n",
       " '062',\n",
       " '062 cloth',\n",
       " '063',\n",
       " '063 shoe',\n",
       " '064',\n",
       " '064 say',\n",
       " '065',\n",
       " '065 tv',\n",
       " '066',\n",
       " '066 sport',\n",
       " '067',\n",
       " '067 veget',\n",
       " '068',\n",
       " '068 fruit',\n",
       " '069',\n",
       " '069 movi',\n",
       " '06th',\n",
       " '06th 1987',\n",
       " '070',\n",
       " '070 magazin',\n",
       " '07072004',\n",
       " '07072004 143958',\n",
       " '071',\n",
       " '071 actor',\n",
       " '072',\n",
       " '072 actress',\n",
       " '073',\n",
       " '073 candi',\n",
       " '074',\n",
       " '074 gum',\n",
       " '074114',\n",
       " '074114 gmt',\n",
       " '074658',\n",
       " '074658 pm',\n",
       " '075',\n",
       " '075 scent',\n",
       " '076',\n",
       " '076 candi',\n",
       " '077',\n",
       " '077 ice',\n",
       " '078',\n",
       " '078 color',\n",
       " '079',\n",
       " '079 season',\n",
       " '080',\n",
       " '080 for',\n",
       " '080 holiday',\n",
       " '081',\n",
       " '081 band',\n",
       " '082',\n",
       " '082 singer',\n",
       " '083',\n",
       " '083 group',\n",
       " '0830am',\n",
       " '0830am ask',\n",
       " '084',\n",
       " '084 rapper',\n",
       " '085',\n",
       " '085 type',\n",
       " '086',\n",
       " '086 thing',\n",
       " '087',\n",
       " '087 place',\n",
       " '088',\n",
       " '088 radio',\n",
       " '089',\n",
       " '089 tv',\n",
       " '09',\n",
       " '09 almost',\n",
       " '090',\n",
       " '090 junk',\n",
       " '091',\n",
       " '091 overal',\n",
       " '091103',\n",
       " '091103 am',\n",
       " '0915',\n",
       " '0915 am',\n",
       " '092',\n",
       " '092 store',\n",
       " '093',\n",
       " '093 shoe',\n",
       " '094',\n",
       " '094 fast',\n",
       " '095',\n",
       " '095 restaur',\n",
       " '096',\n",
       " '096 shape',\n",
       " '097',\n",
       " '097 time',\n",
       " '098',\n",
       " '098 countri',\n",
       " '099',\n",
       " '099 state',\n",
       " '0nbsp',\n",
       " '0nbsp think',\n",
       " '0o',\n",
       " '0o well',\n",
       " '10',\n",
       " '10 11',\n",
       " '10 12',\n",
       " '10 15',\n",
       " '10 22',\n",
       " '10 acquaint',\n",
       " '10 all',\n",
       " '10 am',\n",
       " '10 anyway',\n",
       " '10 año',\n",
       " '10 begin',\n",
       " '10 best',\n",
       " '10 bibl',\n",
       " '10 buck',\n",
       " '10 by',\n",
       " '10 collect',\n",
       " '10 come',\n",
       " '10 cs',\n",
       " '10 day',\n",
       " '10 dec',\n",
       " '10 didnt',\n",
       " '10 dirti',\n",
       " '10 dispos',\n",
       " '10 dress',\n",
       " '10 empir',\n",
       " '10 enough',\n",
       " '10 euro',\n",
       " '10 eurossurprisingli',\n",
       " '10 evil',\n",
       " '10 exactli',\n",
       " '10 foot',\n",
       " '10 friend',\n",
       " '10 fuzzi',\n",
       " '10 ga',\n",
       " '10 game',\n",
       " '10 gener',\n",
       " '10 get',\n",
       " '10 gig',\n",
       " '10 golf',\n",
       " '10 good',\n",
       " '10 grover',\n",
       " '10 he',\n",
       " '10 hey',\n",
       " '10 hole',\n",
       " '10 hour',\n",
       " '10 hr',\n",
       " '10 indic',\n",
       " '10 interview',\n",
       " '10 is',\n",
       " '10 italian',\n",
       " '10 item',\n",
       " '10 join',\n",
       " '10 kkycfm1023',\n",
       " '10 lb',\n",
       " '10 line',\n",
       " '10 lioaz',\n",
       " '10 liter',\n",
       " '10 littl',\n",
       " '10 min',\n",
       " '10 minut',\n",
       " '10 minutesnbsp',\n",
       " '10 month',\n",
       " '10 muahahahaha',\n",
       " '10 much',\n",
       " '10 murder',\n",
       " '10 now',\n",
       " '10 oclock',\n",
       " '10 page',\n",
       " '10 peopl',\n",
       " '10 percent',\n",
       " '10 perhap',\n",
       " '10 pluswtfmak',\n",
       " '10 pm',\n",
       " '10 point',\n",
       " '10 pound',\n",
       " '10 pple',\n",
       " '10 read',\n",
       " '10 resid',\n",
       " '10 rock',\n",
       " '10 second',\n",
       " '10 seriou',\n",
       " '10 she',\n",
       " '10 someth',\n",
       " '10 sport',\n",
       " '10 st',\n",
       " '10 stay',\n",
       " '10 still',\n",
       " '10 straight',\n",
       " '10 strict',\n",
       " '10 the',\n",
       " '10 thing',\n",
       " '10 time',\n",
       " '10 today',\n",
       " '10 usc',\n",
       " '10 wasnt',\n",
       " '10 week',\n",
       " '10 went',\n",
       " '10 when',\n",
       " '10 whether',\n",
       " '10 white',\n",
       " '10 wingstop',\n",
       " '10 worst',\n",
       " '10 ye',\n",
       " '10 year',\n",
       " '10 you',\n",
       " '100',\n",
       " '100 195',\n",
       " '100 and',\n",
       " '100 back',\n",
       " '100 backped',\n",
       " '100 boy',\n",
       " '100 cheaper',\n",
       " '100 clear',\n",
       " '100 correctli',\n",
       " '100 denver',\n",
       " '100 email',\n",
       " '100 foot',\n",
       " '100 go',\n",
       " '100 got',\n",
       " '100 gram',\n",
       " '100 guess',\n",
       " '100 kid',\n",
       " '100 kind',\n",
       " '100 left',\n",
       " '100 like',\n",
       " '100 machin',\n",
       " '100 mark',\n",
       " '100 mile',\n",
       " '100 million',\n",
       " '100 mom',\n",
       " '100 month',\n",
       " '100 nation',\n",
       " '100 page',\n",
       " '100 peopl',\n",
       " '100 pleas',\n",
       " '100 posit',\n",
       " '100 post',\n",
       " '100 pound',\n",
       " '100 round',\n",
       " '100 run',\n",
       " '100 safe',\n",
       " '100 so',\n",
       " '100 thing',\n",
       " '100 thursday',\n",
       " '100 time',\n",
       " '100 today',\n",
       " '100 ton',\n",
       " '100 tonight',\n",
       " '100 yard',\n",
       " '100 year',\n",
       " '1000',\n",
       " '1000 base',\n",
       " '1000 big',\n",
       " '1000 buck',\n",
       " '1000 care',\n",
       " '1000 disney',\n",
       " '1000 doesnt',\n",
       " '1000 exactli',\n",
       " '1000 get',\n",
       " '1000 jesu',\n",
       " '1000 layer',\n",
       " '1000 mile',\n",
       " '1000 morn',\n",
       " '1000 owe',\n",
       " '1000 page',\n",
       " '1000 point',\n",
       " '1000 pound',\n",
       " '1000 summit',\n",
       " '1000 suppos',\n",
       " '1000 the',\n",
       " '1000 time',\n",
       " '1000 usd',\n",
       " '1000 won115',\n",
       " '1000 year',\n",
       " '1000 you',\n",
       " '10000',\n",
       " '10000 bomber',\n",
       " '10000 english',\n",
       " '10000 give',\n",
       " '10000 new',\n",
       " '10000 pair',\n",
       " '10000 sumber',\n",
       " '100000',\n",
       " '100000 1998',\n",
       " '100000 cop',\n",
       " '100000 protestor',\n",
       " '100000 relief',\n",
       " '1000000',\n",
       " '1000000 mile',\n",
       " '1000000 peopl',\n",
       " '1000020000',\n",
       " '1000020000 usd',\n",
       " '10000th',\n",
       " '10000th time',\n",
       " '100010',\n",
       " '100010 am',\n",
       " '100am',\n",
       " '100am thi',\n",
       " '100gb',\n",
       " '100gb drive',\n",
       " '100m',\n",
       " '100m song',\n",
       " '100pre',\n",
       " '100pre hacen',\n",
       " '100th',\n",
       " '100th attempt',\n",
       " '100th birthday',\n",
       " '100th post',\n",
       " '100th store',\n",
       " '101',\n",
       " '101 aday',\n",
       " '101 detroit',\n",
       " '101 everi',\n",
       " '101 girl',\n",
       " '101 john',\n",
       " '101 mark',\n",
       " '101 spoke',\n",
       " '1011',\n",
       " '1011 hr',\n",
       " '1011 year',\n",
       " '10112000',\n",
       " '10112000 urllink',\n",
       " '1012',\n",
       " '1012 hour',\n",
       " '1015',\n",
       " '1015 least',\n",
       " '1015 per',\n",
       " '1015 pm',\n",
       " '1015 second',\n",
       " '1015 year',\n",
       " '10152003',\n",
       " '10152003 025613',\n",
       " '10152003 033100',\n",
       " '10152003 114641',\n",
       " '1015am',\n",
       " '1015am so',\n",
       " '102',\n",
       " '102 mall',\n",
       " '102 monterrey',\n",
       " '1020',\n",
       " '1020 back',\n",
       " '1020 market',\n",
       " '1020 think',\n",
       " '1020 we',\n",
       " '1020 year',\n",
       " '10203',\n",
       " '10203 deal',\n",
       " '102203',\n",
       " '102203 911',\n",
       " '10232003',\n",
       " '10232003 020031',\n",
       " '10232003 125331',\n",
       " '103',\n",
       " '103 11',\n",
       " '103 13',\n",
       " '103 better',\n",
       " '103 kingston',\n",
       " '103 sigh',\n",
       " '103 video',\n",
       " '1030',\n",
       " '1030 almost',\n",
       " '1030 but',\n",
       " '1030 byer',\n",
       " '1030 flight',\n",
       " '1030 like',\n",
       " '1030 so',\n",
       " '1030 tuesday',\n",
       " '1030 wait',\n",
       " '1030 want',\n",
       " '1030am',\n",
       " '1030am everyon',\n",
       " '1031821',\n",
       " '1031821 receiv',\n",
       " '104',\n",
       " '104 kuala',\n",
       " '104 monday',\n",
       " '104 shampoo',\n",
       " '1045',\n",
       " '1045 daze',\n",
       " '1045 im',\n",
       " '1045am',\n",
       " '1045am woohoo',\n",
       " '1046',\n",
       " '1046 dress',\n",
       " '105',\n",
       " '105 board',\n",
       " '105 game',\n",
       " '105 portland',\n",
       " '1052fm',\n",
       " '1052fm seck',\n",
       " '106',\n",
       " '106 annex',\n",
       " '106 comput',\n",
       " '106 panama',\n",
       " '106 pm',\n",
       " '1067',\n",
       " '1067 fm',\n",
       " '107',\n",
       " '107 car',\n",
       " '107 mostli',\n",
       " '107 ton',\n",
       " '107 winston',\n",
       " '108',\n",
       " '108 bottom',\n",
       " '108 guatemala',\n",
       " '108 music',\n",
       " '108 token',\n",
       " '109',\n",
       " '109 mumbai',\n",
       " '109 swear',\n",
       " '1095',\n",
       " '1095 spent',\n",
       " '10950000',\n",
       " '10950000 most',\n",
       " '10am',\n",
       " '10am immedi',\n",
       " '10ambut',\n",
       " '10ambut till',\n",
       " '10freakin45',\n",
       " '10freakin45 like',\n",
       " '10just',\n",
       " '10just wonder',\n",
       " '10midnight',\n",
       " '10midnight one',\n",
       " '10mile',\n",
       " '10mile fun',\n",
       " '10min',\n",
       " '10min one',\n",
       " '10nbsp',\n",
       " '10nbsp like',\n",
       " '10pm',\n",
       " '10pm 1am',\n",
       " '10pm apolog',\n",
       " '10pm especi',\n",
       " '10pm it',\n",
       " '10pm leav',\n",
       " '10pm roll',\n",
       " '10pm the',\n",
       " '10pm went',\n",
       " '10pmet',\n",
       " '10pmet also',\n",
       " '10second',\n",
       " '10second time',\n",
       " '10th',\n",
       " '10th 11th',\n",
       " '10th afterward',\n",
       " '10th anniversari',\n",
       " '10th book',\n",
       " '10th dinner',\n",
       " '10th final',\n",
       " '10th galleri',\n",
       " '10th grade',\n",
       " '10th may',\n",
       " '10th mr',\n",
       " '10th sycamor',\n",
       " '10th urllink',\n",
       " '10th year',\n",
       " '10wordsorless',\n",
       " '10wordsorless instruct',\n",
       " '10x',\n",
       " '10x wors',\n",
       " '10year',\n",
       " '10year 135',\n",
       " '10year period',\n",
       " '10you',\n",
       " '10you know',\n",
       " '11',\n",
       " '11 10',\n",
       " '11 12',\n",
       " '11 15',\n",
       " '11 2001',\n",
       " '11 2253',\n",
       " '11 all',\n",
       " '11 am',\n",
       " '11 beij',\n",
       " '11 color',\n",
       " '11 could',\n",
       " '11 day',\n",
       " '11 er',\n",
       " '11 guess',\n",
       " '11 he',\n",
       " '11 ish',\n",
       " '11 itll',\n",
       " '11 march',\n",
       " '11 mind',\n",
       " '11 miss',\n",
       " '11 morn',\n",
       " '11 next',\n",
       " '11 not',\n",
       " '11 one',\n",
       " '11 par',\n",
       " '11 plu',\n",
       " '11 pm',\n",
       " '11 probe',\n",
       " '11 public',\n",
       " '11 rbi',\n",
       " '11 row',\n",
       " '11 the',\n",
       " '11 virginia',\n",
       " '11 walk',\n",
       " '11 year',\n",
       " '110',\n",
       " '110 bandar',\n",
       " '110 done',\n",
       " '110 mm',\n",
       " '110 word',\n",
       " '1100',\n",
       " '1100 becas',\n",
       " '1100 current',\n",
       " '1100 get',\n",
       " '1100 go',\n",
       " '1100 morn',\n",
       " '1100 train',\n",
       " '11000',\n",
       " '11000 chocol',\n",
       " '11000 microsoft',\n",
       " '11001130',\n",
       " '11001130 bu',\n",
       " '11001300ad',\n",
       " '11001300ad right',\n",
       " '11003',\n",
       " '11003 your',\n",
       " '1100th',\n",
       " '1100th croissant',\n",
       " '1105',\n",
       " '1105 1105',\n",
       " '1105 35',\n",
       " '1108',\n",
       " '1108 as',\n",
       " '111',\n",
       " '111 everyon',\n",
       " '111 lago',\n",
       " '111 month',\n",
       " '1110',\n",
       " '1110 victori',\n",
       " '1111',\n",
       " '1111 seen',\n",
       " '111398',\n",
       " '111398 did',\n",
       " '1118',\n",
       " '1118 pm',\n",
       " '112',\n",
       " '112 calori',\n",
       " '112 cartoon',\n",
       " '112 pittsburgh',\n",
       " '1122',\n",
       " '1122 1222',\n",
       " '1127am',\n",
       " '1127am fast',\n",
       " '112850',\n",
       " '112850 am',\n",
       " '113',\n",
       " '113 montreal',\n",
       " '113 percent',\n",
       " '113 scari',\n",
       " '1130',\n",
       " '1130 amthey',\n",
       " '1130 fall',\n",
       " '1130 plane',\n",
       " '1130 realli',\n",
       " '1130nvmstill',\n",
       " '1130nvmstill irrit',\n",
       " '1130pm730am',\n",
       " '1130pm730am mind',\n",
       " '1130pm730am one',\n",
       " '114',\n",
       " '114 accus',\n",
       " '114 calgari',\n",
       " '114 team',\n",
       " '1140',\n",
       " '1140 finish',\n",
       " '11400',\n",
       " '11400 foot',\n",
       " '1145',\n",
       " '1145 got',\n",
       " '1145pm',\n",
       " '1145pm got',\n",
       " '114641',\n",
       " '114641 am',\n",
       " '115',\n",
       " '115 possess',\n",
       " '115 tianjin',\n",
       " '1150am',\n",
       " '1150am fli',\n",
       " '1155pm',\n",
       " '1155pm catch',\n",
       " '1155pm there',\n",
       " '116',\n",
       " '116 eminem',\n",
       " '116 new',\n",
       " '117',\n",
       " '117 dacca',\n",
       " '117 dog',\n",
       " '118',\n",
       " '118 hot',\n",
       " '118 lima',\n",
       " '119',\n",
       " '119 bangkok',\n",
       " '119 britney',\n",
       " '11am',\n",
       " '11am good',\n",
       " '11am meet',\n",
       " '11am pull',\n",
       " '11nbspfuck',\n",
       " '11nbspfuck you',\n",
       " '11pm',\n",
       " '11pm how',\n",
       " '11pm know',\n",
       " '11pm lioaz',\n",
       " '11pm needless',\n",
       " '11pm someday',\n",
       " '11pm watch',\n",
       " '11th',\n",
       " '11th came',\n",
       " '11th circuit',\n",
       " '11th june',\n",
       " '11th nasa',\n",
       " '11th peopl',\n",
       " '11th there',\n",
       " '12',\n",
       " '12 10',\n",
       " '12 12',\n",
       " '12 13',\n",
       " '12 2003',\n",
       " '12 2b',\n",
       " '12 account',\n",
       " '12 actual',\n",
       " '12 and',\n",
       " '12 biy',\n",
       " '12 block',\n",
       " '12 boyfriend',\n",
       " '12 chrisjo',\n",
       " '12 comp',\n",
       " '12 comput',\n",
       " '12 cup',\n",
       " '12 day',\n",
       " '12 drive',\n",
       " '12 elig',\n",
       " '12 favorit',\n",
       " '12 first',\n",
       " '12 fold',\n",
       " '12 font',\n",
       " '12 foot',\n",
       " '12 game',\n",
       " '12 hi',\n",
       " '12 hot',\n",
       " '12 hour',\n",
       " '12 hr',\n",
       " '12 hrsnbsp',\n",
       " '12 id',\n",
       " '12 know',\n",
       " '12 leg',\n",
       " '12 littl',\n",
       " '12 long',\n",
       " '12 maybechri',\n",
       " '12 mile',\n",
       " '12 million',\n",
       " '12 minut',\n",
       " '12 month',\n",
       " '12 myron',\n",
       " '12 new',\n",
       " '12 oldest',\n",
       " '12 par',\n",
       " '12 percent',\n",
       " '12 pint',\n",
       " '12 popcornscoz',\n",
       " '12 practic',\n",
       " '12 price',\n",
       " '12 script',\n",
       " '12 sec',\n",
       " '12 stimp',\n",
       " '12 student',\n",
       " '12 sunris',\n",
       " '12 teaspoon',\n",
       " '12 they',\n",
       " '12 time',\n",
       " '12 uni',\n",
       " '12 uniqu',\n",
       " '12 volum',\n",
       " '12 way',\n",
       " '12 wear',\n",
       " '12 week',\n",
       " '12 year',\n",
       " '12 your',\n",
       " '12 yr',\n",
       " '120',\n",
       " '120 45',\n",
       " '120 left',\n",
       " '120 mm',\n",
       " '120 nsync',\n",
       " '120 tuni',\n",
       " '1200',\n",
       " '1200 omg',\n",
       " '1200 that',\n",
       " '12000',\n",
       " '12000 btu',\n",
       " '120000',\n",
       " '120000 ground',\n",
       " '121',\n",
       " '121 nairobi',\n",
       " '121 real',\n",
       " '121148',\n",
       " '121148 pm',\n",
       " '1213',\n",
       " '1213 year',\n",
       " '1215',\n",
       " '1215 figur',\n",
       " '1215am',\n",
       " '1215am spent',\n",
       " '1218',\n",
       " '1218 appar',\n",
       " '122',\n",
       " '122 among',\n",
       " '122 orang',\n",
       " '122 tehran',\n",
       " '1222',\n",
       " '1222 130',\n",
       " '12272002',\n",
       " '12272002 930',\n",
       " '123',\n",
       " '123 choic',\n",
       " '123 dont',\n",
       " '123 fame',\n",
       " '123 santiago',\n",
       " '123 weekend',\n",
       " '1230',\n",
       " '1230 330',\n",
       " '1230 everynight',\n",
       " '1230 got',\n",
       " '1230 hour',\n",
       " '1230 time',\n",
       " '1230 want',\n",
       " '1234',\n",
       " '1234 1234',\n",
       " '1234 half',\n",
       " '1234 took',\n",
       " '124',\n",
       " '124 fuck',\n",
       " '124 ottawa',\n",
       " '124 percent',\n",
       " '1240',\n",
       " '1240 time',\n",
       " '1245',\n",
       " '1245 everi',\n",
       " '1245 explos',\n",
       " '1245 pure',\n",
       " '124am',\n",
       " '124am 30',\n",
       " '125',\n",
       " '125 bed',\n",
       " '125 bisexu',\n",
       " '125 lusaka',\n",
       " '125331',\n",
       " '125331 pm',\n",
       " '126',\n",
       " '126 around',\n",
       " '126 black',\n",
       " '126 johannesburg',\n",
       " '127',\n",
       " '127 am',\n",
       " '127 colombo',\n",
       " '127 icq',\n",
       " '128',\n",
       " '128 insan',\n",
       " '128 mb',\n",
       " '128 são',\n",
       " '129',\n",
       " '129 bucharest',\n",
       " '129 linkin',\n",
       " '1295',\n",
       " '1295 top',\n",
       " '12am',\n",
       " '12am 2am',\n",
       " '12am one',\n",
       " '12hour',\n",
       " '12hour interv',\n",
       " '12month',\n",
       " '12month period',\n",
       " '12th',\n",
       " '12th amend',\n",
       " '12th august',\n",
       " '12th christma',\n",
       " '12th grade',\n",
       " '12th it',\n",
       " '12th march',\n",
       " '12th novemb',\n",
       " '12th place',\n",
       " '12yearold',\n",
       " '12yearold target',\n",
       " '13',\n",
       " '13 062',\n",
       " '13 11',\n",
       " '13 14',\n",
       " '13 16',\n",
       " '13 17',\n",
       " '13 day',\n",
       " '13 euro',\n",
       " '13 hi',\n",
       " '13 hour',\n",
       " '13 inning',\n",
       " '13 kiloton',\n",
       " '13 miami',\n",
       " '13 milan',\n",
       " '13 million',\n",
       " '13 mm',\n",
       " '13 movi',\n",
       " '13 play',\n",
       " '13 take',\n",
       " '13 tape',\n",
       " '13 walk',\n",
       " '13 week',\n",
       " '13 year',\n",
       " '13 you',\n",
       " '130',\n",
       " '130 1105',\n",
       " '130 came',\n",
       " '130 dont',\n",
       " '130 end',\n",
       " ...]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the labels - (7.5 points)\n",
    "As we have noticed before, in this task each example can have multiple tags. To deal with such kind of prediction, we need to transform labels in a binary form and the prediction will be a mask of 0s and 1s. For this purpose, it is convenient to use MultiLabelBinarizer from sklearn\n",
    "a.\tConvert your train and test labels using MultiLabelBinarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y_train_multi = mlb.fit_transform(y_train)\n",
    "y_test_multi = mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose a classifier - (5 points)\n",
    "In this task, we suggest using the One-vs-Rest approach, which is implemented in OneVsRestClassifier class. In this approach k classifiers (= number of tags) are trained. As a basic classifier, use LogisticRegression. It is one of the simplest methods, but often it performs good enough in text classification tasks. It might take some time because the number of classifiers to train is large.\n",
    "a.\tUse a linear classifier of your choice, wrap it up in OneVsRestClassifier to train it on every label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='multinomial',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=0, solver='lbfgs',\n",
       "                                                 tol=0.0001, verbose=0,\n",
       "                                                 warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n",
    "classif = OneVsRestClassifier(clf)\n",
    "classif.fit(X_train, y_train_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = classif.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the classifier, make predictions and get the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[[ 961    2]\n",
      "  [  32    5]]\n",
      "\n",
      " [[ 922   10]\n",
      "  [  46   22]]\n",
      "\n",
      " [[ 982    0]\n",
      "  [  18    0]]\n",
      "\n",
      " [[ 916   10]\n",
      "  [  55   19]]\n",
      "\n",
      " [[ 959   12]\n",
      "  [  29    0]]\n",
      "\n",
      " [[ 926    5]\n",
      "  [  50   19]]\n",
      "\n",
      " [[ 945    9]\n",
      "  [  39    7]]\n",
      "\n",
      " [[ 978    0]\n",
      "  [  22    0]]\n",
      "\n",
      " [[ 978    1]\n",
      "  [  15    6]]\n",
      "\n",
      " [[ 978    1]\n",
      "  [  12    9]]\n",
      "\n",
      " [[ 882    9]\n",
      "  [  38   71]]\n",
      "\n",
      " [[ 452  100]\n",
      "  [  48  400]]\n",
      "\n",
      " [[ 987    4]\n",
      "  [   8    1]]\n",
      "\n",
      " [[ 998    0]\n",
      "  [   2    0]]\n",
      "\n",
      " [[ 982    0]\n",
      "  [  16    2]]\n",
      "\n",
      " [[ 999    0]\n",
      "  [   1    0]]\n",
      "\n",
      " [[ 997    0]\n",
      "  [   3    0]]\n",
      "\n",
      " [[1000    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[ 996    1]\n",
      "  [   3    0]]\n",
      "\n",
      " [[ 997    1]\n",
      "  [   2    0]]\n",
      "\n",
      " [[1000    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[ 918   13]\n",
      "  [  46   23]]\n",
      "\n",
      " [[ 404  111]\n",
      "  [  59  426]]\n",
      "\n",
      " [[ 994    0]\n",
      "  [   6    0]]\n",
      "\n",
      " [[ 996    0]\n",
      "  [   4    0]]\n",
      "\n",
      " [[ 995    0]\n",
      "  [   5    0]]\n",
      "\n",
      " [[ 984    2]\n",
      "  [  12    2]]\n",
      "\n",
      " [[ 985    0]\n",
      "  [  13    2]]\n",
      "\n",
      " [[ 980    0]\n",
      "  [  10   10]]\n",
      "\n",
      " [[ 988    1]\n",
      "  [   9    2]]\n",
      "\n",
      " [[ 994    1]\n",
      "  [   5    0]]\n",
      "\n",
      " [[ 969    2]\n",
      "  [  24    5]]\n",
      "\n",
      " [[ 969    5]\n",
      "  [  19    7]]\n",
      "\n",
      " [[ 985    0]\n",
      "  [  15    0]]\n",
      "\n",
      " [[ 995    0]\n",
      "  [   5    0]]\n",
      "\n",
      " [[ 987    1]\n",
      "  [   3    9]]\n",
      "\n",
      " [[ 998    0]\n",
      "  [   2    0]]\n",
      "\n",
      " [[ 960    2]\n",
      "  [  36    2]]\n",
      "\n",
      " [[ 902   14]\n",
      "  [  45   39]]\n",
      "\n",
      " [[1000    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[ 995    1]\n",
      "  [   4    0]]\n",
      "\n",
      " [[ 988    3]\n",
      "  [   7    2]]\n",
      "\n",
      " [[1000    0]\n",
      "  [   0    0]]\n",
      "\n",
      " [[ 834   13]\n",
      "  [  77   76]]\n",
      "\n",
      " [[ 995    0]\n",
      "  [   5    0]]\n",
      "\n",
      " [[ 906    8]\n",
      "  [  71   15]]\n",
      "\n",
      " [[ 982    0]\n",
      "  [   8   10]]\n",
      "\n",
      " [[ 870   16]\n",
      "  [  81   33]]\n",
      "\n",
      " [[ 976    7]\n",
      "  [  17    0]]\n",
      "\n",
      " [[ 449   96]\n",
      "  [  46  409]]\n",
      "\n",
      " [[ 987    4]\n",
      "  [   9    0]]\n",
      "\n",
      " [[ 608   45]\n",
      "  [ 112  235]]\n",
      "\n",
      " [[ 658   57]\n",
      "  [ 123  162]]\n",
      "\n",
      " [[ 235  112]\n",
      "  [  45  608]]]\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.14      0.23        37\n",
      "           1       0.69      0.32      0.44        68\n",
      "           2       0.00      0.00      0.00        18\n",
      "           3       0.66      0.26      0.37        74\n",
      "           4       0.00      0.00      0.00        29\n",
      "           5       0.79      0.28      0.41        69\n",
      "           6       0.44      0.15      0.23        46\n",
      "           7       0.00      0.00      0.00        22\n",
      "           8       0.86      0.29      0.43        21\n",
      "           9       0.90      0.43      0.58        21\n",
      "          10       0.89      0.65      0.75       109\n",
      "          11       0.80      0.89      0.84       448\n",
      "          12       0.20      0.11      0.14         9\n",
      "          13       0.00      0.00      0.00         2\n",
      "          14       1.00      0.11      0.20        18\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         3\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         3\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.64      0.33      0.44        69\n",
      "          22       0.79      0.88      0.83       485\n",
      "          23       0.00      0.00      0.00         6\n",
      "          24       0.00      0.00      0.00         4\n",
      "          25       0.00      0.00      0.00         5\n",
      "          26       0.50      0.14      0.22        14\n",
      "          27       1.00      0.13      0.24        15\n",
      "          28       1.00      0.50      0.67        20\n",
      "          29       0.67      0.18      0.29        11\n",
      "          30       0.00      0.00      0.00         5\n",
      "          31       0.71      0.17      0.28        29\n",
      "          32       0.58      0.27      0.37        26\n",
      "          33       0.00      0.00      0.00        15\n",
      "          34       0.00      0.00      0.00         5\n",
      "          35       0.90      0.75      0.82        12\n",
      "          36       0.00      0.00      0.00         2\n",
      "          37       0.50      0.05      0.10        38\n",
      "          38       0.74      0.46      0.57        84\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.00      0.00      0.00         4\n",
      "          41       0.40      0.22      0.29         9\n",
      "          42       0.00      0.00      0.00         0\n",
      "          43       0.85      0.50      0.63       153\n",
      "          44       0.00      0.00      0.00         5\n",
      "          45       0.65      0.17      0.28        86\n",
      "          46       1.00      0.56      0.71        18\n",
      "          47       0.67      0.29      0.40       114\n",
      "          48       0.00      0.00      0.00        17\n",
      "          49       0.81      0.90      0.85       455\n",
      "          50       0.00      0.00      0.00         9\n",
      "          51       0.84      0.68      0.75       347\n",
      "          52       0.74      0.57      0.64       285\n",
      "          53       0.84      0.93      0.89       653\n",
      "\n",
      "   micro avg       0.80      0.66      0.72      4000\n",
      "   macro avg       0.42      0.23      0.28      4000\n",
      "weighted avg       0.76      0.66      0.68      4000\n",
      " samples avg       0.79      0.66      0.69      4000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "results = multilabel_confusion_matrix(y_test_multi, pred) \n",
    "print('Confusion Matrix :')\n",
    "print(results)\n",
    "print('Report : ')\n",
    "print(classification_report(y_test_multi, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.502\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score :',accuracy_score(y_test_multi, pred))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Statistical NLP_R8_Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
